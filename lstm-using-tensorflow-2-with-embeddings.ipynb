{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Text classification using Tensorflow 2.0 Alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucas/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/lucas/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/lucas/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/lucas/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/lucas/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/lucas/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "POS_TRAIN_PATH = 'data/twitter-datasets/train_pos_full.txt' \n",
    "NEG_TRAIN_PATH = 'data/twitter-datasets/train_neg_full.txt' \n",
    "DATA_TEST_PATH = 'data/twitter-datasets/test_data.txt'\n",
    "OUTPUT_PATH = 'predictions_out.csv'\n",
    "TRAINING_DATA_PATH_X = 'data/training_data.npy'\n",
    "TRAINING_DATA_PATH_Y = 'data/data_y.npy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Tensorflow Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot copy sequence with size 2 to array axis with dimension 20",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-02a8fe60b609>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoAvgVec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAINING_DATA_PATH_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot copy sequence with size 2 to array axis with dimension 20"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(TRAINING_DATA_PATH_X):\n",
    "    train_data = np.load(TRAINING_DATA_PATH_X)\n",
    "    train_y = np.load(TRAINING_DATA_PATH_Y)\n",
    "else:\n",
    "    embeddings = np.load('saved_gen_files/embeddings.npy')\n",
    "\n",
    "    train_text_neg = open(NEG_TRAIN_PATH, 'r').readlines()\n",
    "    train_text_pos = open(POS_TRAIN_PATH, 'r').readlines()\n",
    "    # Construct the two arrays \n",
    "    train_text = np.array(train_text_neg + train_text_pos)\n",
    "    train_y = np.concatenate([np.array([-1 for _ in range(len(train_text_neg))]), np.ones(len(train_text_pos))])\n",
    "\n",
    "    with open('saved_gen_files/vocab.pkl', 'rb') as f:\n",
    "        voc = pickle.load(f)\n",
    "\n",
    "    def toAvgVec(t):\n",
    "\n",
    "        _, K = embeddings.shape\n",
    "        sum_vec = np.zeros((K))\n",
    "        words = t.split()\n",
    "        for word in words:\n",
    "            index = voc.get(word)\n",
    "            if index is not None:\n",
    "                sum_vec += embeddings[index]\n",
    "\n",
    "        return sum_vec/len(words)\n",
    "    # Create numerical feature matrix of tweets\n",
    "    train_data = np.zeros(len(train_text)*embeddings.shape[1]).reshape(len(train_text), 20)\n",
    "    for i in range(len(train_text)):\n",
    "        train_data[i] = [toAvgVec(train_text[i]), train_text[i]]\n",
    "    \n",
    "    np.save(TRAINING_DATA_PATH_X, train_data)\n",
    "    np.save(TRAINING_DATA_PATH_Y, train_y)\n",
    "\n",
    "indices = np.arange(train_data.shape[0])\n",
    "random.shuffle(indices)\n",
    "\n",
    "indices\n",
    "X_train = train_data[indices[:2400000]]\n",
    "y_train = train_y[indices[:2400000]]\n",
    "\n",
    "X_test = train_data[2400000:]\n",
    "y_test = train_y[2400000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400000, 20)\n",
      "(100000, 20)\n"
     ]
    }
   ],
   "source": [
    "max_features = 200\n",
    "num_features = X_test.shape[1] #Size of embedding features\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing classes in  [0, 1] instead of [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[y_train == -1] = 0\n",
    "y_test[y_test == -1] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use only a small fraction of dataset to test the architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120000, 20)\n",
      "(5000, 20)\n"
     ]
    }
   ],
   "source": [
    "ratio = 0.05\n",
    "train_size = int(X_train.shape[0] * ratio)\n",
    "test_size = int(X_test.shape[0] * ratio)\n",
    "X_train = X_train[:train_size]\n",
    "y_train = y_train[:train_size]\n",
    "X_test = X_test[:test_size]\n",
    "y_test = y_test[:test_size]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-15ccadc6779e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0mresult_ndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_axis_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_ndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0msl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define LSTM layers and parameters\n",
    "- Bidirectional LSTM using CUDA GPU processing\n",
    "- No embeddings used currently\n",
    "- Two fully connected layers with dropout layers for reducing chances of overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_28 (Bidirectio (None, None, 64)          13568     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_7 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 14,218\n",
      "Trainable params: 14,218\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "#model1.add(Embedding(input_dim=num_features, output_dim=max_features))\n",
    "#model1.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "#model1.add(GlobalMaxPool1D())\n",
    "#model1.add(Dropout(0.2))\n",
    "#model1.add(Dense(64, activation='softmax'))\n",
    "#model1.add(Dropout(0.2))\n",
    "#model1.add(Dense(32, activation='sigmoid'))\n",
    "#model1.add(Dropout(0.2))\n",
    "model1.add(Bidirectional(LSTM(32, return_sequences=True), input_shape=(20, 2)))\n",
    "model1.add(GlobalMaxPool1D())\n",
    "model1.add(Dense(10, activation='relu'))\n",
    "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit LSTM model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected bidirectional_28_input to have 3 dimensions, but got array with shape (120000, 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-7fd88225192e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#%time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m           distribution_strategy=strategy)\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    548\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m         steps=steps)\n\u001b[0m\u001b[1;32m    595\u001b[0m   adapter = adapter_cls(\n\u001b[1;32m    596\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2470\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2471\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2472\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    563\u001b[0m                            \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    566\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected bidirectional_28_input to have 3 dimensions, but got array with shape (120000, 20)"
     ]
    }
   ],
   "source": [
    "#%time \n",
    "model1.fit(X_train, y_train, batch_size=512, epochs=2, validation_data=(X_test, y_test), verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict using trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130613/130613 [==============================] - 4s 30us/sample\n"
     ]
    }
   ],
   "source": [
    "pred_test_y = model1.predict([X_test], batch_size=1024, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate optimal probability threshold for classification\n",
    "- Calculating best probability cut-off giving the highest F1 - Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score at threshold 0.1 is 0.5891262295756677\n",
      "F1 score at threshold 0.11 is 0.5975954439991563\n",
      "F1 score at threshold 0.12 is 0.6047695027814912\n",
      "F1 score at threshold 0.13 is 0.61223950301802\n",
      "F1 score at threshold 0.14 is 0.6191546762589928\n",
      "F1 score at threshold 0.15 is 0.6253955152015408\n",
      "F1 score at threshold 0.16 is 0.6300181843614491\n",
      "F1 score at threshold 0.17 is 0.6342181490099245\n",
      "F1 score at threshold 0.18 is 0.6384704519119352\n",
      "F1 score at threshold 0.19 is 0.6415761804156636\n",
      "F1 score at threshold 0.2 is 0.6435060397324548\n",
      "F1 score at threshold 0.21 is 0.6468503139558435\n",
      "F1 score at threshold 0.22 is 0.6490045784248162\n",
      "F1 score at threshold 0.23 is 0.6509902283534514\n",
      "F1 score at threshold 0.24 is 0.652383730179774\n",
      "F1 score at threshold 0.25 is 0.6535217321227099\n",
      "F1 score at threshold 0.26 is 0.6549115646258504\n",
      "F1 score at threshold 0.27 is 0.655426997245179\n",
      "F1 score at threshold 0.28 is 0.6556516885291653\n",
      "F1 score at threshold 0.29 is 0.6546298392574145\n",
      "F1 score at threshold 0.3 is 0.6554958252316139\n",
      "F1 score at threshold 0.31 is 0.6553260429323612\n",
      "F1 score at threshold 0.32 is 0.6545007896122127\n",
      "F1 score at threshold 0.33 is 0.6546550094517958\n",
      "F1 score at threshold 0.34 is 0.6548208216564307\n",
      "F1 score at threshold 0.35 is 0.6537906137184115\n",
      "F1 score at threshold 0.36 is 0.6531157089982403\n",
      "F1 score at threshold 0.37 is 0.6508043305400942\n",
      "F1 score at threshold 0.38 is 0.6484288354898337\n",
      "F1 score at threshold 0.39 is 0.6464885021752641\n",
      "F1 score at threshold 0.4 is 0.6450644313774554\n",
      "F1 score at threshold 0.41 is 0.6434651030830338\n",
      "F1 score at threshold 0.42 is 0.6418622400305285\n",
      "F1 score at threshold 0.43 is 0.638185789541308\n",
      "F1 score at threshold 0.44 is 0.6353490786400208\n",
      "F1 score at threshold 0.45 is 0.6314823313446535\n",
      "F1 score at threshold 0.46 is 0.6273912755676178\n",
      "F1 score at threshold 0.47 is 0.6225821564821632\n",
      "F1 score at threshold 0.48 is 0.6175133961880216\n",
      "F1 score at threshold 0.49 is 0.6113555127852626\n",
      "F1 score at threshold 0.5 is 0.6048909635616248\n",
      "Optimal probabilty threshold is 0.28 for maximum F1 score 0.6556516885291653\n"
     ]
    }
   ],
   "source": [
    "opt_prob = None\n",
    "f1_max = 0\n",
    "\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    f1 = metrics.f1_score(y_test, (pred_test_y > thresh).astype(int))\n",
    "    print('F1 score at threshold {} is {}'.format(thresh, f1))\n",
    "    \n",
    "    if f1 > f1_max:\n",
    "        f1_max = f1\n",
    "        opt_prob = thresh\n",
    "        \n",
    "print('Optimal probabilty threshold is {} for maximum F1 score {}'.format(opt_prob, f1_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375806/375806 [==============================] - 11s 29us/sample\n"
     ]
    }
   ],
   "source": [
    "pred_submission_y = model1.predict([X_submission], batch_size=1024, verbose=1)\n",
    "pred_submission_y = (pred_submission_y > opt_prob).astype(int)\n",
    "\n",
    "df_submission = pd.DataFrame({'qid': df_test['qid'].values})\n",
    "df_submission['prediction'] = pred_submission_y\n",
    "#df_submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to load embeddings from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embed(file):\n",
    "    def get_coefs(word,*arr): \n",
    "        return word, np.asarray(arr, dtype='float32')\n",
    "    \n",
    "    if file == '../input/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec':\n",
    "        embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file, encoding=\"utf8\") if len(o)>100)\n",
    "    else:\n",
    "        embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file, encoding='latin'))\n",
    "        \n",
    "    return embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = '../input/embeddings/glove.840B.300d/glove.840B.300d.txt'\n",
    "paragram =  '../input/embeddings/paragram_300_sl999/paragram_300_sl999.txt'\n",
    "wiki_news = '../input/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting GloVe embedding\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting GloVe embedding\")\n",
    "embed_glove = load_embed(glove)\n",
    "#print(\"Extracting Paragram embedding\")\n",
    "#embed_paragram = load_embed(paragram)\n",
    "#print(\"Extracting FastText embedding\")\n",
    "#embed_fasttext = load_embed(wiki_news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Vocabulary and calculating coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(texts):\n",
    "    sentences = texts.apply(lambda x: x.split()).values\n",
    "    vocab = {}\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            try:\n",
    "                vocab[word] += 1\n",
    "            except KeyError:\n",
    "                vocab[word] = 1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_coverage(vocab, embeddings_index):\n",
    "    known_words = {}\n",
    "    unknown_words = {}\n",
    "    nb_known_words = 0\n",
    "    nb_unknown_words = 0\n",
    "    for word in vocab.keys():\n",
    "        try:\n",
    "            known_words[word] = embeddings_index[word]\n",
    "            nb_known_words += vocab[word]\n",
    "        except:\n",
    "            unknown_words[word] = vocab[word]\n",
    "            nb_unknown_words += vocab[word]\n",
    "            pass\n",
    "\n",
    "    print('Found embeddings for {:.2%} of vocab'.format(len(known_words) / len(vocab)))\n",
    "    print('Found embeddings for  {:.2%} of all text'.format(nb_known_words / (nb_known_words + nb_unknown_words)))\n",
    "    unknown_words = sorted(unknown_words.items(), key=operator.itemgetter(1))[::-1]\n",
    "\n",
    "    return unknown_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bulding dataset vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = build_vocab(df['question_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating coverage for each embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove : \n",
      "Found embeddings for 33.02% of vocab\n",
      "Found embeddings for  88.15% of all text\n"
     ]
    }
   ],
   "source": [
    "print(\"Glove : \")\n",
    "oov_glove = check_coverage(vocab, embed_glove)\n",
    "#print(\"Paragram : \")\n",
    "#oov_paragram = check_coverage(vocab, embed_paragram)\n",
    "#print(\"FastText : \")\n",
    "#oov_fasttext = check_coverage(vocab, embed_fasttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(embed_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"'s\": array([-6.8580e-02,  4.6470e-01,  1.3214e-01,  1.8599e-01, -3.7015e-02,\n",
       "         3.2988e-01,  1.7865e-01, -2.5977e-01, -2.6022e-01,  2.5728e+00,\n",
       "        -2.5867e-01, -6.6095e-01,  8.1984e-02,  1.0321e-02, -1.2223e-01,\n",
       "         9.4609e-03, -8.8657e-02,  5.8367e-01, -1.7465e-02, -3.5569e-01,\n",
       "        -1.0182e-01,  6.1941e-02, -1.4267e-01, -4.0544e-01,  2.9834e-01,\n",
       "         1.0003e-01,  3.5899e-02,  2.2920e-01,  3.0278e-01, -1.8259e-01,\n",
       "        -1.1042e-03,  2.5792e-01, -5.4132e-02,  1.5748e-01,  6.1311e-02,\n",
       "        -3.0055e-01,  3.3732e-01,  4.0023e-01,  4.2472e-02, -3.0014e-01,\n",
       "         6.2963e-02,  7.2134e-02,  6.0897e-02, -6.2527e-02,  2.7505e-01,\n",
       "        -1.3527e-01, -2.1710e-01,  1.9315e-02,  3.8683e-02, -1.2361e-01,\n",
       "        -7.7210e-02, -1.1320e-01, -9.3050e-02,  3.5217e-01,  1.9300e-01,\n",
       "         4.8418e-02, -2.0489e-01,  9.6088e-02,  7.7817e-02, -3.7924e-01,\n",
       "         1.1290e-01, -1.8285e-01, -5.6815e-02,  3.7091e-01,  3.2133e-01,\n",
       "        -1.6343e-01, -3.0290e-01,  2.0258e-01, -1.9113e-01, -4.1821e-02,\n",
       "         9.6427e-02,  2.8788e-01,  2.1868e-01,  1.1835e-01, -5.8606e-01,\n",
       "         8.4765e-02,  4.0064e-02,  3.8934e-02, -4.1745e-04,  1.2880e-01,\n",
       "         3.2659e-02,  2.7487e-01,  3.2105e-01,  1.1337e-01,  2.3331e-01,\n",
       "        -2.0270e-01, -7.5498e-01, -2.1488e-01,  1.1081e-01, -1.2337e-01,\n",
       "        -6.8252e-01,  4.6154e-01, -1.8431e-01, -4.0732e-01,  2.9356e-01,\n",
       "         1.8444e-01,  4.6945e-02, -1.6625e-01,  2.8425e-01,  9.8857e-02,\n",
       "         1.4131e-01,  9.9858e-03, -7.7743e-02, -4.1674e-02, -1.6059e-01,\n",
       "         6.6496e-01,  3.8880e-01,  6.1784e-02, -2.3028e-01, -8.5093e-02,\n",
       "         1.5053e-01,  5.0199e-01, -6.0354e-02,  7.8031e-03, -1.0188e-01,\n",
       "         1.8607e-01,  1.1777e-01, -1.5382e-01,  1.7520e-01,  3.4421e-01,\n",
       "         6.1868e-02, -5.8456e-02,  1.9939e-01,  2.4807e-01, -1.2043e-01,\n",
       "         2.4495e-01, -2.2755e-01, -4.4586e-02, -7.8157e-02, -3.7290e-01,\n",
       "        -2.6008e-01, -3.1267e-01,  4.6500e-01, -1.4188e-01, -9.2598e-02,\n",
       "         6.7002e-02,  2.2380e-01,  5.0371e-01, -4.1528e-01, -3.5387e-02,\n",
       "        -1.1150e+00,  1.0314e-01,  1.0069e-01,  2.6980e-01, -8.6038e-02,\n",
       "        -1.8304e-01, -1.1100e-01,  3.3949e-01, -1.5439e-01, -6.0346e-02,\n",
       "        -7.6030e-02,  3.6591e-01,  7.6120e-02,  1.4184e-01, -6.6350e-02,\n",
       "        -4.2175e-01, -6.8802e-01,  1.6540e-01, -1.5966e-01, -8.2361e-02,\n",
       "        -3.7665e-01,  1.5192e-01, -1.5739e-01,  7.5572e-02, -9.3941e-02,\n",
       "        -5.3344e-01,  2.5038e-01, -1.7772e-01,  5.6826e-01,  2.3024e-02,\n",
       "        -1.3049e-01, -2.3437e-01, -1.4206e-01, -3.6676e-01, -8.7881e-01,\n",
       "        -1.7991e-01,  6.1699e-01, -5.4129e-02, -4.1839e-02,  4.4565e-01,\n",
       "         7.1349e-02,  1.1386e-02, -1.3037e-01, -3.6068e-02, -9.1853e-02,\n",
       "         2.8994e-01,  3.5194e-01,  1.8153e-02, -2.7042e-01, -3.8262e-01,\n",
       "        -4.1694e-01,  8.8887e-02, -3.8843e-01,  9.1897e-02, -1.6549e-01,\n",
       "         1.3396e-01,  1.2725e-01, -3.0501e-01, -8.9378e-02,  2.4039e-01,\n",
       "        -2.9861e-01, -1.0235e-02,  1.1287e-02,  3.9926e-02,  2.2518e-01,\n",
       "        -1.4535e-02, -1.4116e-01, -1.0092e-01, -1.1393e-01, -4.2583e-01,\n",
       "        -1.5182e-01, -4.1830e-01,  9.5807e-02, -4.1133e-01,  3.0601e-01,\n",
       "         2.5951e-01, -1.1851e-01, -6.3935e-02, -6.8160e-01, -3.2533e-01,\n",
       "        -3.1124e-01,  2.6500e-01, -1.7040e-01, -1.3757e-01, -1.3244e-01,\n",
       "        -7.3419e-02, -7.9024e-02,  7.2515e-02,  6.9922e-02,  2.9591e-01,\n",
       "        -3.2007e-01,  9.1738e-02, -1.8087e-01,  7.1566e-02, -2.0362e-01,\n",
       "        -1.9141e-01, -8.5196e-02, -4.7908e-01,  6.4813e-02, -2.1795e-01,\n",
       "        -9.4415e-02,  5.3729e-01,  8.3135e-03,  2.4061e-01,  4.5261e-02,\n",
       "        -8.1265e-02, -3.8758e-02,  1.1975e-01, -1.0087e-01, -2.2780e-01,\n",
       "        -6.6300e-02, -6.9051e-02,  2.6849e-01, -1.6083e-01, -1.6018e-01,\n",
       "         2.6183e-01, -5.4176e-01,  3.1235e-02,  1.4158e-01,  1.4993e-01,\n",
       "        -3.1776e-01,  2.0251e-01, -5.0593e-02,  1.4712e-01, -1.6181e-02,\n",
       "         6.5722e-02, -7.6293e-02, -3.6481e-01,  4.4407e-01, -6.6691e-02,\n",
       "         4.6171e-01,  3.9474e-02, -4.4825e-01, -4.0562e-01,  1.2919e-01,\n",
       "         3.5828e-02, -2.9879e-02,  2.5034e-02,  2.5427e-01,  1.7060e-01,\n",
       "         2.3547e-01,  4.6183e-01, -7.1739e-02,  1.1056e-01, -5.0868e-01,\n",
       "         1.5953e-01, -1.9542e-01,  2.2428e-01, -9.8993e-02, -3.0309e-01,\n",
       "         1.3260e-01,  1.5582e-01,  2.1946e-01, -1.5946e-02,  1.6345e-01,\n",
       "        -2.6763e-01,  4.2565e-02, -9.4786e-02,  2.8878e-01, -2.5244e-01],\n",
       "       dtype=float32),\n",
       " 'it': array([ 1.3629e-03,  3.5653e-01, -5.5497e-02, -1.6607e-01,  3.1402e-03,\n",
       "        -6.1926e-02, -2.4759e-01, -2.2897e-01, -9.1050e-02,  2.6751e+00,\n",
       "        -1.5062e-01,  7.2403e-02,  6.1949e-03, -6.5698e-03, -2.6418e-01,\n",
       "        -1.9543e-01, -1.5048e-01,  1.2156e+00, -1.2551e-01, -1.2572e-01,\n",
       "         2.3065e-02,  2.4727e-02,  1.4311e-01,  1.0148e-01, -1.0566e-01,\n",
       "         7.8640e-02, -1.0306e-01, -1.1968e-01,  4.2020e-02, -3.6815e-01,\n",
       "        -8.7136e-02,  3.8589e-01,  4.4597e-03, -1.8259e-01, -1.2260e-01,\n",
       "        -1.0454e-01,  1.6039e-01,  2.7415e-01,  4.2427e-02, -4.9497e-02,\n",
       "         4.1286e-02,  1.2223e-01,  1.0821e-01, -5.6199e-02,  2.1754e-01,\n",
       "         1.0983e-01, -3.8878e-01, -1.0935e-01, -3.6647e-01,  1.3420e-01,\n",
       "        -7.6634e-02,  3.8148e-01, -1.9979e-01,  9.3910e-02,  3.5189e-01,\n",
       "        -1.1133e-01,  9.5313e-02, -2.9593e-01,  2.9022e-01, -1.9660e-01,\n",
       "        -1.0331e-01, -2.1995e-01, -4.1991e-02,  1.6631e-01,  1.5230e-02,\n",
       "        -2.9185e-01, -5.4720e-02, -4.0665e-02,  8.4861e-02, -9.2060e-03,\n",
       "         2.4625e-01,  8.1873e-02,  3.4256e-01, -1.6768e-01, -7.9394e-02,\n",
       "         1.3206e-01,  2.1560e-01, -1.1199e-01, -3.9589e-01,  3.2299e-01,\n",
       "         8.9602e-02, -2.6041e-02, -2.3981e-01,  4.9861e-02,  5.5241e-02,\n",
       "        -5.0554e-01,  2.3002e-01, -5.4613e-01,  5.8194e-01,  9.6957e-02,\n",
       "        -1.5559e-02,  6.9833e-02, -9.6680e-03,  1.9936e-01,  1.9006e-01,\n",
       "         3.2913e-01, -6.4844e-02, -2.2404e-01, -3.1196e-02,  1.8180e-01,\n",
       "        -7.1896e-02, -7.2126e-02, -8.2155e-02,  6.4145e-02,  1.1215e-01,\n",
       "        -1.0712e+00,  2.9581e-01,  8.1019e-02, -2.4954e-01, -8.7734e-02,\n",
       "         1.5893e-02, -1.5779e-01,  5.5281e-02, -8.0948e-02, -1.1288e-01,\n",
       "         9.9631e-02, -1.7395e-01,  1.2230e-01, -9.9904e-02, -2.0707e-01,\n",
       "        -1.4483e-02, -1.0597e-01, -3.1063e-03,  4.3320e-02, -2.0624e-01,\n",
       "         2.5975e-01, -1.2992e-01, -3.2278e-01,  1.7298e-01, -1.5952e-01,\n",
       "        -1.9577e-01, -2.2784e-01,  2.2428e-02,  1.9393e-01, -5.9827e-02,\n",
       "        -1.1456e-02,  1.7045e-01, -4.1847e-02, -1.2880e-01, -6.7707e-02,\n",
       "        -1.9181e+00,  2.9674e-01,  2.7561e-01,  2.9993e-01,  1.7498e-01,\n",
       "        -2.5321e-01, -2.0170e-01,  1.3409e-01, -4.9065e-02,  1.3186e-01,\n",
       "        -1.0889e-01,  2.3631e-01,  1.7895e-01,  2.4289e-02,  9.2826e-03,\n",
       "        -2.9032e-01, -2.7692e-01, -2.2906e-01, -1.3153e-01,  1.0656e-01,\n",
       "        -2.5672e-01,  1.2929e-01,  1.0399e-01, -9.8408e-02, -4.2153e-01,\n",
       "        -1.3320e-01,  9.1175e-02,  4.0061e-02,  2.0840e-01, -1.7849e-01,\n",
       "        -5.7709e-02, -1.0256e-01, -9.5817e-02, -4.3439e-01, -6.4794e-02,\n",
       "         1.2916e-01,  8.5435e-02, -3.7460e-01, -6.9798e-02,  2.0042e-02,\n",
       "         4.1425e-02, -2.1527e-02, -8.6333e-02, -9.5633e-03,  2.5466e-02,\n",
       "        -1.6101e-01, -8.9574e-02, -2.1178e-01,  8.8594e-02,  8.7381e-02,\n",
       "         5.2047e-02, -2.0386e-01, -2.9424e-01,  1.0097e-01,  7.6137e-02,\n",
       "         1.0431e-01, -1.9752e-01, -3.4268e-01,  5.8982e-02,  2.6035e-01,\n",
       "        -1.6364e-01,  3.2940e-02, -3.0368e-01,  7.3400e-02,  7.1074e-02,\n",
       "         1.7129e-01, -1.4442e-01, -4.1817e-02,  2.0912e-01,  3.2747e-02,\n",
       "        -1.0649e-01, -3.3475e-01,  8.8305e-03, -3.2619e-01,  2.1179e-01,\n",
       "         2.9881e-01, -1.3775e-02, -9.0821e-02, -3.3841e-01, -1.1290e-01,\n",
       "         1.2137e-01,  5.9202e-02, -1.2133e-01, -9.3398e-02,  1.5426e-01,\n",
       "        -3.2649e-02, -1.1216e-01,  2.8842e-01, -3.6565e-02, -4.1662e-02,\n",
       "        -2.2413e-01,  6.0877e-02,  2.1641e-01,  3.0208e-01,  1.6084e-01,\n",
       "        -2.7118e-02,  2.6084e-01, -9.0324e-02, -1.0360e-01, -1.9010e-02,\n",
       "         3.4244e-01,  2.5017e-02,  2.5958e-02,  2.1387e-01,  4.3512e-01,\n",
       "        -6.7789e-01, -3.9166e-03, -3.0027e-01, -5.8978e-02,  1.7072e-01,\n",
       "         1.4497e-01, -1.9255e-01,  1.3603e-01, -1.6038e-01, -7.5959e-02,\n",
       "         2.2820e-01,  2.0681e-01, -1.1637e-02,  8.6048e-02, -3.4803e-02,\n",
       "         2.3821e-01,  2.1667e-01,  1.0353e-01, -1.2959e-02,  3.6174e-01,\n",
       "        -1.2104e-01, -3.3488e-02, -3.0755e-02,  4.3549e-01,  1.8960e-01,\n",
       "         4.5975e-01, -3.4826e-01, -1.6406e-01, -1.2197e-01, -6.4298e-02,\n",
       "         1.9573e-01,  1.7949e-02, -1.2379e-01, -8.1198e-03,  4.0020e-01,\n",
       "         1.7065e-01, -1.0712e-01,  8.8398e-02, -1.1473e-01, -6.9708e-02,\n",
       "        -9.3210e-02,  2.5621e-01, -3.5815e-02,  1.5968e-01, -3.7266e-01,\n",
       "        -2.4035e-01, -8.9325e-02,  1.0603e-01, -1.6025e-01, -5.4419e-02,\n",
       "        -3.0824e-01, -2.6249e-01, -1.1237e-01,  7.8259e-02,  2.2398e-01],\n",
       "       dtype=float32)}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(embed_glove.items())[20:22])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text pre-processing to improve coverage of embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lower casing questions for uniform matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed_question'] = df['question_text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_low = build_vocab(df['processed_question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove : \n",
      "Found embeddings for 27.38% of vocab\n",
      "Found embeddings for  87.87% of all text\n"
     ]
    }
   ],
   "source": [
    "print(\"Glove : \")\n",
    "oov_glove = check_coverage(vocab_low, embed_glove)\n",
    "#print(\"Paragram : \")\n",
    "#oov_paragram = check_coverage(vocab_low, embed_paragram)\n",
    "#print(\"FastText : \")\n",
    "#oov_fasttext = check_coverage(vocab_low, embed_fasttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"what's\", 13369),\n",
       " ('it?', 13158),\n",
       " (\"i'm\", 12814),\n",
       " ('do?', 8766),\n",
       " ('life?', 7791),\n",
       " ('why?', 7369),\n",
       " ('you?', 6314),\n",
       " ('me?', 6241),\n",
       " ('them?', 6141),\n",
       " ('time?', 5742),\n",
       " ('world?', 5525),\n",
       " ('people?', 5008),\n",
       " ('quora?', 4657),\n",
       " ('like?', 4490),\n",
       " ('for?', 4450),\n",
       " ('work?', 4219),\n",
       " ('2017?', 4050),\n",
       " ('mean?', 3980),\n",
       " ('2018?', 3594)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oov_glove[1:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding lower case words to embeddings if missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lower(embedding, vocab):\n",
    "    count = 0\n",
    "    for word in vocab:\n",
    "        if word in embedding and word.lower() not in embedding:  \n",
    "            embedding[word.lower()] = embedding[word]\n",
    "            count += 1\n",
    "    print(f\"Added {count} words to embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove : \n",
      "Added 14725 words to embedding\n"
     ]
    }
   ],
   "source": [
    "print(\"Glove : \")\n",
    "add_lower(embed_glove, vocab)\n",
    "#print(\"Paragram : \")\n",
    "#add_lower(embed_paragram, vocab)\n",
    "#print(\"FastText : \")\n",
    "#add_lower(embed_fasttext, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove : \n",
      "Found embeddings for 30.64% of vocab\n",
      "Found embeddings for  88.19% of all text\n"
     ]
    }
   ],
   "source": [
    "print(\"Glove : \")\n",
    "oov_glove = check_coverage(vocab_low, embed_glove)\n",
    "#print(\"Paragram : \")\n",
    "#oov_paragram = check_coverage(vocab_low, embed_paragram)\n",
    "#print(\"FastText : \")\n",
    "#oov_fasttext = check_coverage(vocab_low, embed_fasttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"what's\", 13369),\n",
       " ('it?', 13158),\n",
       " ('do?', 8766),\n",
       " ('life?', 7791),\n",
       " ('why?', 7369),\n",
       " ('you?', 6314),\n",
       " ('me?', 6241),\n",
       " ('them?', 6141),\n",
       " ('time?', 5742),\n",
       " ('world?', 5525),\n",
       " ('people?', 5008),\n",
       " ('quora?', 4657),\n",
       " ('like?', 4490),\n",
       " ('for?', 4450),\n",
       " ('work?', 4219),\n",
       " ('2017?', 4050),\n",
       " ('mean?', 3980),\n",
       " ('2018?', 3594),\n",
       " (\"isn't\", 3509)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oov_glove[1:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing special characters appropriately\n",
    "- This ensures better a match to embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(x):\n",
    "\n",
    "    x = str(x)\n",
    "    for punct in \"/-'\":\n",
    "        x = x.replace(punct, ' ')\n",
    "    for punct in punctuations:\n",
    "        x = x.replace(punct, '')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1306122/1306122 [00:14<00:00, 90639.58it/s]\n"
     ]
    }
   ],
   "source": [
    "df[\"processed_question\"] = df[\"processed_question\"].progress_apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_low = build_vocab(df['processed_question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove : \n",
      "Found embeddings for 65.90% of vocab\n",
      "Found embeddings for  99.44% of all text\n"
     ]
    }
   ],
   "source": [
    "print(\"Glove : \")\n",
    "oov_glove = check_coverage(vocab_low, embed_glove)\n",
    "#print(\"Paragram : \")\n",
    "#oov_paragram = check_coverage(vocab_low, embed_paragram)\n",
    "#print(\"FastText : \")\n",
    "#oov_fasttext = check_coverage(vocab_low, embed_fasttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['question_text'] = df['processed_question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting dataframe with shape (1306122, 4) into training and test datasets\n",
      "Filling missing values\n",
      "Tokenizing 1306122 questions into words\n",
      "Padding sequences for uniform dimensions\n",
      "Completed data preparation, returning training, test and submission datasets, split as dependent(X) and independent(Y) variables\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, X_submission = data_prep(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilizing embeddings in LSTM classifier\n",
    "- Following a similar model network structure as previous for comparable results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 20, 20)            400       \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 20, 256)           152576    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 171,537\n",
      "Trainable params: 171,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "#model1.add(Embedding(max_features, embed_size, input_length=maxlen, weights = [embed_glove]))\n",
    "model1.add(Embedding(max_features, embed_size, input_length=maxlen))\n",
    "model1.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model1.add(GlobalMaxPool1D())\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(64, activation='relu'))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(32, activation='relu'))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit LSTM model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400000 samples, validate on 100000 samples\n",
      "Epoch 1/5\n",
      "    512/2400000 [..............................] - ETA: 7:57:52"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " indices[301,1] = -1 is not in [0, 20)\n\t [[node sequential_4/embedding_1/embedding_lookup (defined at /home/lucas/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1751) ]] [Op:__inference_distributed_function_9597]\n\nFunction call stack:\ndistributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  indices[301,1] = -1 is not in [0, 20)\n\t [[node sequential_4/embedding_1/embedding_lookup (defined at /home/lucas/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1751) ]] [Op:__inference_distributed_function_9597]\n\nFunction call stack:\ndistributed_function\n"
     ]
    }
   ],
   "source": [
    "%time model1.fit(X_train, y_train, batch_size=512, epochs=5, validation_data=(X_test, y_test), verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict using trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130613/130613 [==============================] - 4s 31us/sample\n"
     ]
    }
   ],
   "source": [
    "pred_test_y = model1.predict([X_test], batch_size=1024, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate optimal probability threshold for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score at threshold 0.1 is 0.5871446772988884\n",
      "F1 score at threshold 0.11 is 0.5923871718030147\n",
      "F1 score at threshold 0.12 is 0.5976102857662078\n",
      "F1 score at threshold 0.13 is 0.6009870393432036\n",
      "F1 score at threshold 0.14 is 0.6051867802640202\n",
      "F1 score at threshold 0.15 is 0.6078347780777793\n",
      "F1 score at threshold 0.16 is 0.6100589730066645\n",
      "F1 score at threshold 0.17 is 0.6129376394142179\n",
      "F1 score at threshold 0.18 is 0.6157241649909265\n",
      "F1 score at threshold 0.19 is 0.6175640200108969\n",
      "F1 score at threshold 0.2 is 0.6203893699014064\n",
      "F1 score at threshold 0.21 is 0.6222963412168991\n",
      "F1 score at threshold 0.22 is 0.623558232111871\n",
      "F1 score at threshold 0.23 is 0.6246069790216998\n",
      "F1 score at threshold 0.24 is 0.6243496357960457\n",
      "F1 score at threshold 0.25 is 0.6243692178301093\n",
      "F1 score at threshold 0.26 is 0.6256432019521511\n",
      "F1 score at threshold 0.27 is 0.6261102193686463\n",
      "F1 score at threshold 0.28 is 0.6273006962811032\n",
      "F1 score at threshold 0.29 is 0.6275726886638353\n",
      "F1 score at threshold 0.3 is 0.6286780851998243\n",
      "F1 score at threshold 0.31 is 0.628293652985693\n",
      "F1 score at threshold 0.32 is 0.6270402763077265\n",
      "F1 score at threshold 0.33 is 0.6272441651705565\n",
      "F1 score at threshold 0.34 is 0.6264611214636626\n",
      "F1 score at threshold 0.35 is 0.6263430163151612\n",
      "F1 score at threshold 0.36 is 0.6263736263736265\n",
      "F1 score at threshold 0.37 is 0.6256770773308747\n",
      "F1 score at threshold 0.38 is 0.6253984814235206\n",
      "F1 score at threshold 0.39 is 0.6248614594878377\n",
      "F1 score at threshold 0.4 is 0.6241933591458407\n",
      "F1 score at threshold 0.41 is 0.6228696113699358\n",
      "F1 score at threshold 0.42 is 0.6220351043643264\n",
      "F1 score at threshold 0.43 is 0.6208171786459885\n",
      "F1 score at threshold 0.44 is 0.6204454048862478\n",
      "F1 score at threshold 0.45 is 0.6189412687873483\n",
      "F1 score at threshold 0.46 is 0.6182590233545647\n",
      "F1 score at threshold 0.47 is 0.6183126944427499\n",
      "F1 score at threshold 0.48 is 0.6178921568627451\n",
      "F1 score at threshold 0.49 is 0.6161336044863499\n",
      "F1 score at threshold 0.5 is 0.6152798415056958\n",
      "Optimal probabilty threshold is 0.3 for maximum F1 score 0.6286780851998243\n"
     ]
    }
   ],
   "source": [
    "opt_prob = None\n",
    "f1_max = 0\n",
    "\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    f1 = metrics.f1_score(y_test, (pred_test_y > thresh).astype(int))\n",
    "    print('F1 score at threshold {} is {}'.format(thresh, f1))\n",
    "    \n",
    "    if f1 > f1_max:\n",
    "        f1_max = f1\n",
    "        opt_prob = thresh\n",
    "        \n",
    "print('Optimal probabilty threshold is {} for maximum F1 score {}'.format(opt_prob, f1_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375806/375806 [==============================] - 11s 29us/sample\n"
     ]
    }
   ],
   "source": [
    "pred_submission_y = model1.predict([X_submission], batch_size=1024, verbose=1)\n",
    "pred_submission_y = (pred_submission_y > opt_prob).astype(int)\n",
    "\n",
    "df_submission = pd.DataFrame({'qid': df_test['qid'].values})\n",
    "df_submission['prediction'] = pred_submission_y\n",
    "df_submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Improvements:\n",
    "- Optimizing LSTM hyperparameters\n",
    "- Optimizing LSTM network structure (adding LSTM, dense, maxpooling etc. layers)\n",
    "- Text processing to further improve embeddings coverage\n",
    "- Using all 3 embeddings together/combining the weighted output of 3 LSTM models using each embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
